{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (col, lead, hour, dayofweek, when, sin, cos, lit)\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, FloatType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386fb106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark session started\n",
      "Using dataset: /home/sarantis/Documents/Spark_Project/csv/usage_summary.csv\n",
      "Model will be saved to: /home/sarantis/Documents/Spark_Project/machine_learning/model_next_hour_rf\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"BikeUtilizationNextHour\")\n",
    "    .master(\"local[*]\")            \n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")  \n",
    "print(\"âœ… Spark session started\")\n",
    "\n",
    "BASE = os.getcwd()\n",
    "DATASET = os.path.join(BASE, \"..\", \"csv\", \"usage_summary.csv\")\n",
    "MODEL_DIR = os.path.join(BASE, \"model_next_hour_rf\")\n",
    "\n",
    "print(\"Using dataset:\", os.path.abspath(DATASET))\n",
    "print(\"Model will be saved to:\", os.path.abspath(MODEL_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f259aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paths and schema ready\n",
      "+-------------------+-------------------+-----+-------------------+--------+-------------------+-------------------+--------+--------+----------+--------+\n",
      "|window_start       |window_end         |city |avg_util           |max_util|min_util           |std_util           |avg_temp|avg_wind|avg_clouds|avg_rain|\n",
      "+-------------------+-------------------+-----+-------------------+--------+-------------------+-------------------+--------+--------+----------+--------+\n",
      "|2024-10-01 00:00:00|2024-10-01 00:30:00|Dubai|0.12701971200407824|0.7     |0.0751488588740989 |0.13780409198416974|13.35   |4.02    |4.52      |0.0     |\n",
      "|2024-10-01 00:30:00|2024-10-01 01:00:00|Dubai|0.20358897827893918|0.7     |0.11718720278539041|0.11376687028255095|15.51   |3.93    |9.86      |0.0     |\n",
      "|2024-10-01 01:00:00|2024-10-01 01:30:00|Dubai|0.2890309473644737 |0.7     |0.2380438898149237 |0.10407713343927097|14.9    |3.86    |34.62     |0.0     |\n",
      "|2024-10-01 01:30:00|2024-10-01 02:00:00|Dubai|0.40579189746248095|0.7     |0.34096014961998916|0.23209246254544472|15.71   |7.09    |27.77     |0.0     |\n",
      "|2024-10-01 02:00:00|2024-10-01 02:30:00|Dubai|0.373608649224309  |0.7     |0.24743176215842758|0.1832196723415582 |16.04   |1.8     |24.09     |0.0     |\n",
      "+-------------------+-------------------+-----+-------------------+--------+-------------------+-------------------+--------+--------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"window_start\", TimestampType(), True),\n",
    "    StructField(\"window_end\", TimestampType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"avg_util\", DoubleType(), True),\n",
    "    StructField(\"max_util\", DoubleType(), True),\n",
    "    StructField(\"min_util\", DoubleType(), True),\n",
    "    StructField(\"std_util\", DoubleType(), True),\n",
    "    StructField(\"avg_temp\", DoubleType(), True),\n",
    "    StructField(\"avg_wind\", DoubleType(), True),\n",
    "    StructField(\"avg_clouds\", DoubleType(), True),\n",
    "    StructField(\"avg_rain\", DoubleType(), True)\n",
    "])\n",
    "print(\"âœ… Paths and schema ready\")\n",
    "\n",
    "df = spark.read.csv(DATASET, header=True, schema=schema)\n",
    "df = df.orderBy(col(\"window_start\").asc())\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47a8fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Future (t+1h) features created!\n",
      "+-------------------+-------------------+-----+-------------------+--------+-------------------+-------------------+--------+--------+----------+--------+--------+--------+--------+----------+-------------------+-------------------+\n",
      "|window_start       |window_end         |city |avg_util           |max_util|min_util           |std_util           |avg_temp|avg_wind|avg_clouds|avg_rain|temp_t1h|wind_t1h|rain_t1h|clouds_t1h|time_t1h           |util_t1h           |\n",
      "+-------------------+-------------------+-----+-------------------+--------+-------------------+-------------------+--------+--------+----------+--------+--------+--------+--------+----------+-------------------+-------------------+\n",
      "|2024-10-01 00:00:00|2024-10-01 00:30:00|Dubai|0.12701971200407824|0.7     |0.0751488588740989 |0.13780409198416974|13.35   |4.02    |4.52      |0.0     |14.9    |3.86    |0.0     |34.62     |2024-10-01 01:00:00|0.2890309473644737 |\n",
      "|2024-10-01 00:30:00|2024-10-01 01:00:00|Dubai|0.20358897827893918|0.7     |0.11718720278539041|0.11376687028255095|15.51   |3.93    |9.86      |0.0     |15.71   |7.09    |0.0     |27.77     |2024-10-01 01:30:00|0.40579189746248095|\n",
      "|2024-10-01 01:00:00|2024-10-01 01:30:00|Dubai|0.2890309473644737 |0.7     |0.2380438898149237 |0.10407713343927097|14.9    |3.86    |34.62     |0.0     |16.04   |1.8     |0.0     |24.09     |2024-10-01 02:00:00|0.373608649224309  |\n",
      "|2024-10-01 01:30:00|2024-10-01 02:00:00|Dubai|0.40579189746248095|0.7     |0.34096014961998916|0.23209246254544472|15.71   |7.09    |27.77     |0.0     |15.04   |4.75    |0.0     |26.08     |2024-10-01 02:30:00|0.33421889791042925|\n",
      "|2024-10-01 02:00:00|2024-10-01 02:30:00|Dubai|0.373608649224309  |0.7     |0.24743176215842758|0.1832196723415582 |16.04   |1.8     |24.09     |0.0     |17.2    |3.71    |0.0     |25.36     |2024-10-01 03:00:00|0.3388498498501162 |\n",
      "+-------------------+-------------------+-----+-------------------+--------+-------------------+-------------------+--------+--------+----------+--------+--------+--------+--------+----------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w = Window.orderBy(col(\"window_start\").asc())\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    # weather forecast at t+1h (2 rows later â†’ 1 hour)\n",
    "    .withColumn(\"temp_t1h\",  lead(\"avg_temp\",  2).over(w))\n",
    "    .withColumn(\"wind_t1h\",  lead(\"avg_wind\",  2).over(w))\n",
    "    .withColumn(\"rain_t1h\",  lead(\"avg_rain\",  2).over(w))\n",
    "    .withColumn(\"clouds_t1h\",lead(\"avg_clouds\",2).over(w))\n",
    "    \n",
    "    # timestamp of the prediction moment (t+1h)\n",
    "    .withColumn(\"time_t1h\",  lead(\"window_start\", 2).over(w))\n",
    "\n",
    "    # LABEL we want to predict: bike utilization at t+1h\n",
    "    .withColumn(\"util_t1h\",  lead(\"avg_util\", 2).over(w))\n",
    ")\n",
    "\n",
    "df = df.na.drop(subset=[\"temp_t1h\", \"wind_t1h\", \"rain_t1h\", \"time_t1h\", \"util_t1h\"])\n",
    "print(\"âœ… Future (t+1h) features created!\")\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c2cc4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Time feature engineering completed!\n",
      "+-------------------+--------+-------+--------------+\n",
      "|time_t1h           |hour_t1h|dow_t1h|is_weekend_t1h|\n",
      "+-------------------+--------+-------+--------------+\n",
      "|2024-10-01 01:00:00|1       |3      |0.0           |\n",
      "|2024-10-01 01:30:00|1       |3      |0.0           |\n",
      "|2024-10-01 02:00:00|2       |3      |0.0           |\n",
      "|2024-10-01 02:30:00|2       |3      |0.0           |\n",
      "|2024-10-01 03:00:00|3       |3      |0.0           |\n",
      "+-------------------+--------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"hour_t1h\", hour(col(\"time_t1h\")))\n",
    "df = df.withColumn(\"dow_t1h\", dayofweek(col(\"time_t1h\")))  \n",
    "\n",
    "df = df.withColumn(\n",
    "    \"is_weekend_t1h\",\n",
    "    when(col(\"dow_t1h\").isin([1, 7]), 1.0).otherwise(0.0)\n",
    ")\n",
    "\n",
    "print(\"âœ… Time feature engineering completed!\")\n",
    "df.select(\n",
    "    \"time_t1h\", \"hour_t1h\", \"dow_t1h\", \"is_weekend_t1h\",\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accc9bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['temp_t1h', 'wind_t1h', 'rain_t1h', 'clouds_t1h', 'hour_t1h', 'is_weekend_t1h']\n",
      "Predicted feature: util_t1h\n",
      "âœ… Train rows: 2391  |  Test rows: 535\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    \"temp_t1h\",\n",
    "    \"wind_t1h\",\n",
    "    \"rain_t1h\",\n",
    "    \"clouds_t1h\",\n",
    "    \"hour_t1h\",\n",
    "    \"is_weekend_t1h\"\n",
    "]\n",
    "prediction = \"util_t1h\"\n",
    "\n",
    "print(\"Selected features:\", feature_cols)\n",
    "print(\"Predicted feature:\", prediction)\n",
    "\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"âœ… Train rows: {train_df.count()}  |  Test rows: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f46eb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline created (VectorAssembler + RandomForestRegressor)\n",
      "âœ… Model training complete!\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=prediction,\n",
    "    numTrees=120,\n",
    "    maxDepth=8,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "print(\"âœ… Pipeline created (VectorAssembler + RandomForestRegressor)\")\n",
    "\n",
    "model = pipeline.fit(train_df)\n",
    "print(\"âœ… Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda064c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Evaluation Results:\n",
      "RMSE: 0.0737\n",
      "RÂ² Score: 0.7270\n",
      "MAE Score: 0.0585\n",
      "+-------------------+-------------------+-------------------+\n",
      "|util_t1h           |prediction         |time_t1h           |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|0.373608649224309  |0.3471921085700041 |2024-10-01 02:00:00|\n",
      "|0.36164196735399173|0.26448494309054454|2024-10-01 04:00:00|\n",
      "|0.23944004308866432|0.2623739858991277 |2024-10-01 05:00:00|\n",
      "|0.3467799459866746 |0.26906287343220936|2024-10-01 07:30:00|\n",
      "|0.005486111199901  |0.18013925670490202|2024-10-01 10:30:00|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.transform(test_df)\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=prediction,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=prediction,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=prediction,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\"\n",
    ")\n",
    "\n",
    "rmse = rmse_evaluator.evaluate(test_predictions)\n",
    "r2 = r2_evaluator.evaluate(test_predictions)\n",
    "mae = mae_evaluator.evaluate(test_predictions)\n",
    "\n",
    "print(\"âœ… Model Evaluation Results:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "print(f\"MAE Score: {mae:.4f}\")\n",
    "\n",
    "test_predictions.select(\n",
    "    \"util_t1h\", \"prediction\", \"time_t1h\"\n",
    ").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8578eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to: /home/sarantis/Documents/Spark_Project/machine_learning/model_next_hour_rf\n",
      "\n",
      "ðŸ§ª Example: On-demand prediction\n",
      "+-------------------+--------+--------+--------+--------+--------------+\n",
      "|time_t1h           |temp_t1h|wind_t1h|rain_t1h|hour_t1h|is_weekend_t1h|\n",
      "+-------------------+--------+--------+--------+--------+--------------+\n",
      "|2024-11-30 23:30:00|18.84   |7.36    |0.0     |23      |1.0           |\n",
      "+-------------------+--------+--------+--------+--------+--------------+\n",
      "\n",
      "\n",
      "ðŸš´â€â™‚ï¸ Predicted utilization for next hour: 0.1085\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(MODEL_DIR):\n",
    "    shutil.rmtree(MODEL_DIR)  \n",
    "\n",
    "model.write().overwrite().save(MODEL_DIR)\n",
    "\n",
    "print(f\"âœ… Model saved to: {os.path.abspath(MODEL_DIR)}\")\n",
    "\n",
    "latest = df.orderBy(col(\"time_t1h\").desc()).limit(1)\n",
    "\n",
    "print(\"\\nðŸ§ª Example: On-demand prediction\")\n",
    "latest.select(\n",
    "    \"time_t1h\", \"temp_t1h\", \"wind_t1h\", \"rain_t1h\", \"hour_t1h\", \"is_weekend_t1h\"\n",
    ").show(truncate=False)\n",
    "\n",
    "predicted = model.transform(latest).select(\"prediction\").collect()[0][0]\n",
    "\n",
    "print(f\"\\nðŸš´â€â™‚ï¸ Predicted utilization for next hour: {predicted:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3a9282d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m pdf = test_predictions.select(\u001b[33m\"\u001b[39m\u001b[33mutil_t1h\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtime_t1h\u001b[39m\u001b[33m\"\u001b[39m).toPandas()\n\u001b[32m      2\u001b[39m pdf = pdf.sort_values(\u001b[33m\"\u001b[39m\u001b[33mtime_t1h\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      5\u001b[39m plt.plot(pdf[\u001b[33m\"\u001b[39m\u001b[33mtime_t1h\u001b[39m\u001b[33m\"\u001b[39m], pdf[\u001b[33m\"\u001b[39m\u001b[33mutil_t1h\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mActual Utilization\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.plot(pdf[\u001b[33m\"\u001b[39m\u001b[33mtime_t1h\u001b[39m\u001b[33m\"\u001b[39m], pdf[\u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mPredicted Utilization\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "pdf = test_predictions.select(\"util_t1h\", \"prediction\", \"time_t1h\").toPandas()\n",
    "pdf = pdf.sort_values(\"time_t1h\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(pdf[\"time_t1h\"], pdf[\"util_t1h\"], label=\"Actual Utilization\")\n",
    "plt.plot(pdf[\"time_t1h\"], pdf[\"prediction\"], label=\"Predicted Utilization\")\n",
    "plt.title(\"Actual vs Predicted Utilization Over Time\")\n",
    "plt.xlabel(\"Time (t+1h)\")\n",
    "plt.ylabel(\"Utilization\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13923fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(pdf[\"util_t1h\"], pdf[\"prediction\"])\n",
    "plt.title(\"Actual vs Predicted Utilization Scatter Plot\")\n",
    "plt.xlabel(\"Actual Utilization\")\n",
    "plt.ylabel(\"Predicted Utilization\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
