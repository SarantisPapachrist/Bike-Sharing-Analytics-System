ğŸš´â€â™‚ï¸ Real-Time Bike Sharing Analytics & Forecasting â€” Dubai

An end-to-end real-time data pipeline that collects Dubaiâ€™s public bike sharing data (GBFS standard) and live weather conditions. Data flows through Kafka, is processed via Spark Structured Streaming, aggregated into meaningful analytics, and then used to train a predictive model that forecasts station utilization one hour ahead.

ğŸŒ System Overview
â€¢ GBFS API â†’ public bike station info + status updates
â€¢ OpenWeather API â†’ real-time weather conditions

ğŸ“Œ Technologies
| Layer                  | Tool                              |
| ---------------------- | --------------------------------- |
| Ingestion              | Python, Requests, dotenv          |
| Messaging              | Apache Kafka                      |
| Data Stream Processing | Apache Spark Structured Streaming |
| Storage                | Local CSV output (future: DB)     |
| ML Forecasting         | PySpark MLlib Random Forest       |
| Monitoring             | Logging + console batch prints    |

ğŸ§© Pipeline Architecture
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ GBFS API       â”‚      â”‚ Weather API  â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                         â”‚
          â–¼                         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Producers   â”‚         â”‚ Weather Prod. â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                        |  
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ station_info  â”‚        â”‚ weather       â”‚
   â”‚ station_status|â”€â”€â”€â”€â”€â”€â”€â”€â”˜               |  
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Spark Streaming (Join + Aggregation) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ usage_summary.csv â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ML: Random Forest Model â”‚ â†’ Prediction +1h
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“¡ Streaming Analytics
- Joins real-time station status with static station metadata
- Computes station utilization: utilization = bikes_available / (bikes_available + docks_available)
- Aggregates every 30 minutes: avg, min, max, std deviation of utilization, weather conditions per time window
- Stores analytics to: csv/usage_summary.csv

ğŸ¤– Machine Learning Forecasting
Model: Random Forest Regressor
Goal: Predict next-hour average utilization

ğŸ“Œ Input Features
- Time-of-day, weekend flag
- Temperature, Wind, Clouds, Rain
- Utilization patterns with window shifts
ğŸ“Œ Output Target
- Bike utilization +1 hour later

ğŸ—‚ï¸ Project Structure

Spark_Project/
â”œâ”€â”€ streaming/
â”‚   â””â”€â”€ hourly_analytics_stream.py
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ station_info.py
â”‚   â”œâ”€â”€ station_status.py
â”‚   â””â”€â”€ weather.py
â”œâ”€â”€ producers/
â”‚   â”œâ”€â”€ producer_info.py
â”‚   â”œâ”€â”€ producer_status.py
â”‚   â””â”€â”€ weather_producer.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ random_forest.ipynb
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ http_client.py
â”œâ”€â”€ diagrams/
â”‚   â””â”€â”€ architecture.png
â”œâ”€â”€ csv/usage_summary.csv                  
â”œâ”€â”€ env/.env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

â–¶ï¸ How to Run
1. Start Kafka (two terminals)
cd ~/kafka_2.13-3.8.0
bin/zookeeper-server-start.sh config/zookeeper.properties
bin/kafka-server-start.sh config/server.properties

2. Start producers
python producers/producer_info.py
python producers/producer_status.py
python producers/weather_producer.py

3. Run Analytics Stream
python streaming/hourly_analytics_stream.py